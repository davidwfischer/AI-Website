<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">

    <title>History</title>
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="Style.css">
</head>

<body>
    <nav>
        <a href="AllgemeineInfo.html">← </a>
        <a href="index.html">Start</a>
        <a href="Funktionsweise.html">→ </a>
    </nav>
    <h1>History</h1>
    <h2>
        How did large language models come about?</h2>
    <p>
    <ul>
        <p>
            <li> Static models and language models (1970s - 1990s):</li> In the 1970s and 1980s, statistical models for language processing were introduced, improving natural language processing (NLP). Hidden Markov Models and n-gram models were some of the early approaches. Nevertheless, these models were often limited to specific use cases.

        </p>
        <p>
            <li>
                Rise of neural networks (2000s):</li> With the advent of more powerful computers and
            With larger data sets, neural networks, particularly Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, have experienced a boom. These models enabled better modeling of sequences and demonstrated improved capabilities in language processing.
            <img id="img6" src="pktw.jpg" alt="Uhr">
        </p>
        <p>
            <li>Transformer-Architektur (2017):</li> A crucial turning point was the introduction of the
            Transformer architecture
            in the paper “Attention is All You Need” by Vaswani et al. in 2017. Transformer revolutionized the way models process sequences by relying on attention mechanisms. This architecture allowed for more efficient processing of information in large data sets.
        </p>
        <li>GPT-3 and Superlatives (2020):</li> In 2020, OpenAI released GPT-3, a massive LLM at 175 billion
        parameters. GPT-3 set new standards in language understanding, generation and processing. It
        was able to solve complex tasks and generate human-like text.
    </ul>
    </p>

    <p>
    <h2 id="Timeline">Timeline</h2>
    <img id="img5" src="timeline1.jpg" alt="Timeline">
    <p class="container">

        The evolution of Large Language Models (LLMs) began with ELIZA, an early chatbot in the 1960s. In the 2010s,
        Transformer architectures like BERT marked a milestone in natural language processing. GPT-3 by OpenAI (2019),
        with
        trillions of parameters, is the latest example of LLMs playing a crucial role in various applications.
    </p>
    </p>
</body>

</html>